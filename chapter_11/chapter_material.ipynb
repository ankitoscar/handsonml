{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_material.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPu/2UOP0Quf4S3w767cO8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitoscar/handsonml/blob/main/chapter_11/chapter_material.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-F8JOD2xPlm"
      },
      "source": [
        "## Building an image classifier using the Sequential API \n",
        "Here, we will make an image classifier using keras' Sequential API. The image classifier would be made for the Fashion MNIST dataset which has 70,000 grayscales of different fashion items having size 28 x 28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLHIUnDE0suJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588bc584-aa06-45cc-d899-2916470ef7a0"
      },
      "source": [
        "# Importing libraries \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRuL6Fwj02Nt"
      },
      "source": [
        "# Loading the Fashion MNIST dataset \n",
        "fashion_mnist = keras.datasets.fashion_mnist # Utility function for loading \n",
        "                                             # common dataset \n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "                                            # Splitting data into train and test"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KASeJr71oIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2aae060-3f1f-4235-c500-40ff3bfda2ca"
      },
      "source": [
        "# Shapes and datatype of dataset \n",
        "print(X_train_full.shape)\n",
        "print(X_train_full.dtype)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0JPC31H2YG1"
      },
      "source": [
        "# Dividing the full training dataset to a train and valid set with scaling \n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255\n",
        "                  # Dividing by 255 to scale the input \n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDopvG0j4pLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9d388c8-8324-4e89-d9e3-8de84576a0c4"
      },
      "source": [
        "# Making labels list \n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
        "class_names[y_train[0]] # Class of y_train[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBhyhm86TU7"
      },
      "source": [
        "# Making the neural network using Sequential API \n",
        "model = keras.models.Sequential() # Initialising the model \n",
        "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax')) # Output layer"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB0Pit4m_uAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fb0455-c3b2-4fc2-f2e0-e2065396f473"
      },
      "source": [
        "# Summary of the model showing layers, types, trainable and non-trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is3MXcL-_--Q"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = 'sgd',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1cWpyRuCcaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481667bc-da9b-485b-b2e2-a0b9fdd69ea4"
      },
      "source": [
        "# Training and evaluating the model \n",
        "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 1.0012 - accuracy: 0.6805 - val_loss: 0.5010 - val_accuracy: 0.8336\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5036 - accuracy: 0.8243 - val_loss: 0.4403 - val_accuracy: 0.8506\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4538 - accuracy: 0.8416 - val_loss: 0.4225 - val_accuracy: 0.8522\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4209 - accuracy: 0.8500 - val_loss: 0.4018 - val_accuracy: 0.8632\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3950 - accuracy: 0.8603 - val_loss: 0.3744 - val_accuracy: 0.8718\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3792 - accuracy: 0.8654 - val_loss: 0.3861 - val_accuracy: 0.8686\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3616 - accuracy: 0.8727 - val_loss: 0.3622 - val_accuracy: 0.8752\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3579 - accuracy: 0.8710 - val_loss: 0.3654 - val_accuracy: 0.8700\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3448 - accuracy: 0.8760 - val_loss: 0.3729 - val_accuracy: 0.8642\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3316 - accuracy: 0.8801 - val_loss: 0.3873 - val_accuracy: 0.8616\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3242 - accuracy: 0.8845 - val_loss: 0.3450 - val_accuracy: 0.8766\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3143 - accuracy: 0.8869 - val_loss: 0.3676 - val_accuracy: 0.8662\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3138 - accuracy: 0.8860 - val_loss: 0.3327 - val_accuracy: 0.8836\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3040 - accuracy: 0.8887 - val_loss: 0.3253 - val_accuracy: 0.8846\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2934 - accuracy: 0.8959 - val_loss: 0.3339 - val_accuracy: 0.8804\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2953 - accuracy: 0.8929 - val_loss: 0.3177 - val_accuracy: 0.8850\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2808 - accuracy: 0.8995 - val_loss: 0.3248 - val_accuracy: 0.8878\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2742 - accuracy: 0.9008 - val_loss: 0.3052 - val_accuracy: 0.8898\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2724 - accuracy: 0.9018 - val_loss: 0.3081 - val_accuracy: 0.8906\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2663 - accuracy: 0.9048 - val_loss: 0.3087 - val_accuracy: 0.8920\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2638 - accuracy: 0.9048 - val_loss: 0.3058 - val_accuracy: 0.8918\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2621 - accuracy: 0.9064 - val_loss: 0.3047 - val_accuracy: 0.8908\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2549 - accuracy: 0.9067 - val_loss: 0.2986 - val_accuracy: 0.8960\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2524 - accuracy: 0.9097 - val_loss: 0.3021 - val_accuracy: 0.8928\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2445 - accuracy: 0.9123 - val_loss: 0.2987 - val_accuracy: 0.8952\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9131 - val_loss: 0.2967 - val_accuracy: 0.8948\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2371 - accuracy: 0.9159 - val_loss: 0.2980 - val_accuracy: 0.8924\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2346 - accuracy: 0.9147 - val_loss: 0.3188 - val_accuracy: 0.8878\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2302 - accuracy: 0.9170 - val_loss: 0.2980 - val_accuracy: 0.8922\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2277 - accuracy: 0.9191 - val_loss: 0.2960 - val_accuracy: 0.8936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k36H9sDEnn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "fa4b9223-3d7c-4955-ebb1-84f6790203e9"
      },
      "source": [
        "# Plotting the parameters of the trained model \n",
        "\n",
        "# Importing libraries \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a dataframe of the history object \n",
        "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # Set vertical range from 0-1\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWBPQmEiGihY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e152a1da-66be-4267-84fa-2697739a81ef"
      },
      "source": [
        "# Evaluating the model \n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 63.8217 - accuracy: 0.8451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[63.821693420410156, 0.8450999855995178]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCnnj-AMHVAl"
      },
      "source": [
        "The model has performed with an accuracy of 86% on the test set, which shows that the model is able to generalise easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc2M3zBsHjps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7ec5cc-9600-4df8-b811-fb03d8e4d35c"
      },
      "source": [
        "# Predicting on data using the model \n",
        "\n",
        "# Importing numpy \n",
        "import numpy as np\n",
        "\n",
        "print(model.predict(X_test[:3]))\n",
        "y_pred = model.predict_classes(X_test[:3])\n",
        "print(np.array(class_names)[y_pred])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f881f9d7d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "['Ankle Boot' 'Pullover' 'Trouser']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rTQHnM8JEZf"
      },
      "source": [
        "## Building a Regression model using the Sequential API\n",
        "Here, we will make a regression model on the California housing problem using a neural network. This is a simpler dataset as it has only numerical values in stored in columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POjLEzfjIFzy"
      },
      "source": [
        "# Importing dataset from Scikit-Learn\n",
        "from sklearn.datasets import fetch_california_housing \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Loading the dataset using utility function \n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# Splitting the data into train, test and valid sets \n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data\n",
        "                                                              , housing.target)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "# Initialising scaler to scale the data \n",
        "scaler = StandardScaler() \n",
        "\n",
        "# Scaling the data \n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MplwZCSvJ6RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e67fddd-cdcb-4e99-fb34-79fdf23388b3"
      },
      "source": [
        "# Making the model \n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
        "        keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data = (X_valid, y_valid))\n",
        "\n",
        "# Evaluating \n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test[:3])\n",
        "print(y_pred)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.3281 - val_loss: 1.1616\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 1.2852 - val_loss: 0.5077\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4642\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4500\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.4457\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4194\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3733 - val_loss: 0.4464\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4137 - val_loss: 0.4311\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.4145\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.4141\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.4083\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.4031\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.4018\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.4089\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.4030\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3521 - val_loss: 0.4773\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3987\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3970\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4009\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3878\n",
            "162/162 [==============================] - 0s 783us/step - loss: 27.7593\n",
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f881f0b59e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[ 1.0369828 ]\n",
            " [13.464748  ]\n",
            " [ 0.99790907]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2L1mL7L2zN"
      },
      "source": [
        "## Building complex models using the Functional API\n",
        "Keras also has another API called Functional API, which can be used to create non-sequential models. Here, we will make one such model using it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46AvItaYPzQt"
      },
      "source": [
        "### Wide and Deep Network\n",
        "This neural network tries to create two paths between input and output as to obtain output via a long and a short path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEkI6zLvQOrr"
      },
      "source": [
        "# Making a wide and deep network \n",
        "_input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(_input_) # Using Functional API\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([_input_, hidden2]) # Creating long and short path\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[_input_], outputs=[output])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E6tLUX2RLM3",
        "outputId": "1d27fdb7-ca03-4549-cb63-ec79b4180a8e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 30)           270         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 30)           930         dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 38)           0           input_7[0][0]                    \n",
            "                                                                 dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1)            39          concatenate_4[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bt7pbj4TRNA",
        "outputId": "638cd556-c5d2-4f55-8995-093790f80bea"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "# Training the model \n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.2648 - val_loss: 4.6976\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 1.3278 - val_loss: 93.7802\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRdy76TLTsz2",
        "outputId": "4a6307b4-3305-4e83-c1b3-18d6361cd4e4"
      },
      "source": [
        "# Predicting on test data \n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test[:3])\n",
        "print(y_pred)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 794us/step - loss: nan\n",
            "WARNING:tensorflow:7 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f881efbba70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyrHl6BHWBZ6"
      },
      "source": [
        "We can also configure the neural network to take different subsets of features in different paths and then give the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzy1MWseXgS1"
      },
      "source": [
        "# Making a network to take different features in different paths \n",
        "input_A = keras.layers.Input(shape = [5])\n",
        "input_B = keras.layers.Input(shape = [6])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNHcBhJGYWj9",
        "outputId": "6da070d1-e15d-41c6-a8f2-e43bdf0c5f28"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 30)           210         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 30)           930         dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 35)           0           input_8[0][0]                    \n",
            "                                                                 dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 1)            36          concatenate_5[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nbxhkXUYefz",
        "outputId": "7ce07995-5eb8-44b4-d287-7cff3b568c08"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "# Modifying input shapes of data \n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "# Training the model \n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A,X_valid_B), y_valid))\n",
        "# Evaluating \n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.2986 - val_loss: 0.8496\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.6403 - val_loss: 0.5643\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5184\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4774 - val_loss: 0.5094\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4800\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4663\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4609\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4067 - val_loss: 0.4516\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4485\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4331\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4358\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4497\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.4070\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3838 - val_loss: 0.4243\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.4079\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.4075\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3964\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.4314\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3516 - val_loss: 0.3858\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3999\n",
            "162/162 [==============================] - 0s 878us/step - loss: 7.8352\n",
            "WARNING:tensorflow:8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f881ee4bdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BmBSzpZ4-u"
      },
      "source": [
        "# Making a neural network to give more than one output \n",
        "input_A = keras.layers.Input(shape = [5])\n",
        "input_B = keras.layers.Input(shape = [6])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "aux_output = keras.layers.Dense(1)(hidden2) # auxilary output \n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVTgEYLmbPXE",
        "outputId": "b4683835-5b05-4327-c9dd-bc5f7054caea"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 30)           210         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 30)           930         dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 35)           0           input_10[0][0]                   \n",
            "                                                                 dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 1)            36          concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 1)            31          dense_30[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,207\n",
            "Trainable params: 1,207\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKRbGTopbRTr",
        "outputId": "34ac2ebb-7865-4d34-87f8-613d7a0a3523"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss = ['mse', 'mse'],loss_weights=[0.9, 0.1], optimizer = 'sgd')\n",
        "\n",
        "# Training the model \n",
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "    validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        ")\n",
        "\n",
        "# Getting all losses\n",
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test]\n",
        ")\n",
        "\n",
        "print(total_loss, main_loss, aux_loss)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.9730 - dense_31_loss: 1.8198 - dense_32_loss: 3.3513 - val_loss: 1.3523 - val_dense_31_loss: 1.3453 - val_dense_32_loss: 1.4151\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.9589 - dense_31_loss: 0.9212 - dense_32_loss: 1.2980 - val_loss: 27.7902 - val_dense_31_loss: 29.5598 - val_dense_32_loss: 11.8637\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan - val_loss: nan - val_dense_31_loss: nan - val_dense_32_loss: nan\n",
            "162/162 [==============================] - 0s 1ms/step - loss: nan - dense_31_loss: nan - dense_32_loss: nan\n",
            "nan nan nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f81kbFhxcm1f"
      },
      "source": [
        "## Building a model using Subclassing API\n",
        "In, this method we can wrap our model around a class which can help us to do operations on it like loops, if-statements, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soA2MbTgkX09"
      },
      "source": [
        "# Building a model with Subclassing API\n",
        "class WideAndDeep(keras.models.Model):\n",
        "  def __init__(self, units=30, activation='relu', **kwargs): # constructor\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "    self.main_output = keras.layers.Dense(1)\n",
        "    self.aux_output = keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    input_A, input_B = inputs \n",
        "    hidden1 = self.hidden1(input_B)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    concat = keras.layers.concatenate([input_A, hidden2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden2)\n",
        "    \n",
        "    return main_output, aux_output\n",
        "\n",
        "model = WideAndDeep()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUQmkSaBljqp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}