{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_material.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNT5rLrZ8chySiAIwyZE+iq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitoscar/handsonml/blob/main/chapter_11/chapter_material.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-F8JOD2xPlm"
      },
      "source": [
        "## Building an image classifier using the Sequential API \n",
        "Here, we will make an image classifier using keras' Sequential API. The image classifier would be made for the Fashion MNIST dataset which has 70,000 grayscales of different fashion items having size 28 x 28."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLHIUnDE0suJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e6d1ad-19c7-43a5-b692-19110616f786"
      },
      "source": [
        "# Importing libraries \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRuL6Fwj02Nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb112d9-6cab-4af3-ca83-2965fe0fbc94"
      },
      "source": [
        "# Loading the Fashion MNIST dataset \n",
        "fashion_mnist = keras.datasets.fashion_mnist # Utility function for loading \n",
        "                                             # common dataset \n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "                                            # Splitting data into train and test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KASeJr71oIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0473be-777e-41d1-b282-9a0ccb91a920"
      },
      "source": [
        "# Shapes and datatype of dataset \n",
        "print(X_train_full.shape)\n",
        "print(X_train_full.dtype)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0JPC31H2YG1"
      },
      "source": [
        "# Dividing the full training dataset to a train and valid set with scaling \n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255\n",
        "                  # Dividing by 255 to scale the input \n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDopvG0j4pLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1b729a8-3aaf-4e42-aff7-bc68afd3ecf4"
      },
      "source": [
        "# Making labels list \n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
        "class_names[y_train[0]] # Class of y_train[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBhyhm86TU7"
      },
      "source": [
        "# Making the neural network using Sequential API \n",
        "model = keras.models.Sequential() # Initialising the model \n",
        "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax')) # Output layer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB0Pit4m_uAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b57db03-fa57-454c-95ee-9cd61aff2a5d"
      },
      "source": [
        "# Summary of the model showing layers, types, trainable and non-trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is3MXcL-_--Q"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = 'sgd',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1cWpyRuCcaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f2ca1f-513a-4a4d-b9b1-bc2772e99c91"
      },
      "source": [
        "# Training and evaluating the model \n",
        "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0085 - accuracy: 0.6771 - val_loss: 0.5098 - val_accuracy: 0.8328\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5102 - accuracy: 0.8236 - val_loss: 0.4546 - val_accuracy: 0.8428\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4499 - accuracy: 0.8408 - val_loss: 0.4078 - val_accuracy: 0.8628\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4186 - accuracy: 0.8546 - val_loss: 0.4126 - val_accuracy: 0.8562\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4074 - accuracy: 0.8557 - val_loss: 0.3851 - val_accuracy: 0.8654\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3848 - accuracy: 0.8660 - val_loss: 0.3767 - val_accuracy: 0.8666\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3712 - accuracy: 0.8711 - val_loss: 0.3647 - val_accuracy: 0.8720\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3531 - accuracy: 0.8765 - val_loss: 0.3427 - val_accuracy: 0.8764\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3437 - accuracy: 0.8790 - val_loss: 0.3475 - val_accuracy: 0.8806\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3402 - accuracy: 0.8798 - val_loss: 0.3467 - val_accuracy: 0.8786\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3239 - accuracy: 0.8835 - val_loss: 0.3469 - val_accuracy: 0.8686\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3179 - accuracy: 0.8862 - val_loss: 0.3308 - val_accuracy: 0.8848\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3122 - accuracy: 0.8879 - val_loss: 0.3270 - val_accuracy: 0.8836\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3048 - accuracy: 0.8913 - val_loss: 0.3255 - val_accuracy: 0.8850\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2985 - accuracy: 0.8928 - val_loss: 0.3172 - val_accuracy: 0.8876\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2859 - accuracy: 0.8975 - val_loss: 0.3147 - val_accuracy: 0.8864\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2832 - accuracy: 0.8987 - val_loss: 0.3301 - val_accuracy: 0.8808\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2809 - accuracy: 0.8972 - val_loss: 0.3105 - val_accuracy: 0.8846\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.9016 - val_loss: 0.2999 - val_accuracy: 0.8924\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2646 - accuracy: 0.9059 - val_loss: 0.3232 - val_accuracy: 0.8838\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2587 - accuracy: 0.9070 - val_loss: 0.2974 - val_accuracy: 0.8944\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2574 - accuracy: 0.9068 - val_loss: 0.2979 - val_accuracy: 0.8968\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2564 - accuracy: 0.9078 - val_loss: 0.3143 - val_accuracy: 0.8896\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9119 - val_loss: 0.2964 - val_accuracy: 0.8938\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2426 - accuracy: 0.9129 - val_loss: 0.2927 - val_accuracy: 0.8958\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2435 - accuracy: 0.9132 - val_loss: 0.3029 - val_accuracy: 0.8898\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2366 - accuracy: 0.9149 - val_loss: 0.2918 - val_accuracy: 0.8968\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2364 - accuracy: 0.9149 - val_loss: 0.2966 - val_accuracy: 0.8954\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2298 - accuracy: 0.9175 - val_loss: 0.2942 - val_accuracy: 0.8966\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2218 - accuracy: 0.9195 - val_loss: 0.3745 - val_accuracy: 0.8650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k36H9sDEnn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "a3d7a293-0e01-4008-f774-6d26cdb7f11b"
      },
      "source": [
        "# Plotting the parameters of the trained model \n",
        "\n",
        "# Importing libraries \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a dataframe of the history object \n",
        "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # Set vertical range from 0-1\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWBPQmEiGihY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc3e09-ee6b-467a-998c-88a8a299e32d"
      },
      "source": [
        "# Evaluating the model \n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 71.5840 - accuracy: 0.8386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[71.58397674560547, 0.8385999798774719]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCnnj-AMHVAl"
      },
      "source": [
        "The model has performed with an accuracy of 86% on the test set, which shows that the model is able to generalise easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc2M3zBsHjps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c829634-fd06-4664-a2d6-e26943d009aa"
      },
      "source": [
        "# Predicting on data using the model \n",
        "\n",
        "# Importing numpy \n",
        "import numpy as np\n",
        "\n",
        "print(model.predict(X_test[:3]))\n",
        "y_pred = model.predict_classes(X_test[:3])\n",
        "print(np.array(class_names)[y_pred])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "['Ankle Boot' 'Pullover' 'Trouser']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rTQHnM8JEZf"
      },
      "source": [
        "## Building a Regression model using the Sequential API\n",
        "Here, we will make a regression model on the California housing problem using a neural network. This is a simpler dataset as it has only numerical values in stored in columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POjLEzfjIFzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4339a354-79f9-4743-daed-08746eb48796"
      },
      "source": [
        "# Importing dataset from Scikit-Learn\n",
        "from sklearn.datasets import fetch_california_housing \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Loading the dataset using utility function \n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# Splitting the data into train, test and valid sets \n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data\n",
        "                                                              , housing.target)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "# Initialising scaler to scale the data \n",
        "scaler = StandardScaler() \n",
        "\n",
        "# Scaling the data \n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MplwZCSvJ6RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c911498-36e8-4681-98fd-21464db8354b"
      },
      "source": [
        "# Making the model \n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
        "        keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data = (X_valid, y_valid))\n",
        "\n",
        "# Evaluating \n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test[:3])\n",
        "print(y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.3061 - val_loss: 0.6226\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5687 - val_loss: 0.5330\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4830 - val_loss: 0.4989\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.4821\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4198 - val_loss: 0.4749\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4327 - val_loss: 0.4693\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4228 - val_loss: 0.4543\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4506\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4162 - val_loss: 0.4427\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4417\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.4381\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.4345\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3881 - val_loss: 0.4319\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4291\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.4310\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3762 - val_loss: 0.4321\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3652 - val_loss: 0.4328\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3620 - val_loss: 0.4214\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3794 - val_loss: 0.4442\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3725 - val_loss: 0.4237\n",
            "162/162 [==============================] - 0s 831us/step - loss: 1.4633\n",
            "[[3.946719 ]\n",
            " [0.7343684]\n",
            " [0.5957064]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2L1mL7L2zN"
      },
      "source": [
        "## Building complex models using the Functional API\n",
        "Keras also has another API called Functional API, which can be used to create non-sequential models. Here, we will make one such model using it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46AvItaYPzQt"
      },
      "source": [
        "### Wide and Deep Network\n",
        "This neural network tries to create two paths between input and output as to obtain output via a long and a short path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEkI6zLvQOrr"
      },
      "source": [
        "# Making a wide and deep network \n",
        "_input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(_input_) # Using Functional API\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([_input_, hidden2]) # Creating long and short path\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[_input_], outputs=[output])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E6tLUX2RLM3",
        "outputId": "45492d41-c365-4d23-93ae-0fe284bf5792"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
            "                                                                 dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,239\n",
            "Trainable params: 1,239\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bt7pbj4TRNA",
        "outputId": "c63c57f3-4e13-4fe0-f335-9f0382a468dc"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "# Training the model \n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 5.9959 - val_loss: 9.8144\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 2.6658 - val_loss: 109.4731\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRdy76TLTsz2",
        "outputId": "f2f21917-b15f-47b9-be7b-4b87011d7dae"
      },
      "source": [
        "# Predicting on test data \n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test[:3])\n",
        "print(y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 918us/step - loss: nan\n",
            "[[nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyrHl6BHWBZ6"
      },
      "source": [
        "We can also configure the neural network to take different subsets of features in different paths and then give the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzy1MWseXgS1"
      },
      "source": [
        "# Making a network to take different features in different paths \n",
        "input_A = keras.layers.Input(shape = [5])\n",
        "input_B = keras.layers.Input(shape = [6])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNHcBhJGYWj9",
        "outputId": "a8c37373-d6d5-4487-88a3-2d8d13727dc6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 30)           210         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 35)           0           input_2[0][0]                    \n",
            "                                                                 dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            36          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nbxhkXUYefz",
        "outputId": "ceba8be4-e756-42bc-ab37-1b0850037e64"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "# Modifying input shapes of data \n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "# Training the model \n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_A,X_valid_B), y_valid))\n",
        "# Evaluating \n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.4294 - val_loss: 0.5394\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.5009\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4437 - val_loss: 0.6258\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4638 - val_loss: 0.4991\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4361 - val_loss: 0.4641\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4341 - val_loss: 0.4584\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4478\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3917 - val_loss: 0.4545\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3656 - val_loss: 0.4376\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3786 - val_loss: 0.4350\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3804 - val_loss: 0.4339\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3891 - val_loss: 0.4255\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3667 - val_loss: 0.4415\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3825 - val_loss: 0.4267\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3746 - val_loss: 0.4201\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3571 - val_loss: 0.4172\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3639 - val_loss: 0.4390\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3544 - val_loss: 0.4083\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3550 - val_loss: 0.4266\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3551 - val_loss: 0.4105\n",
            "162/162 [==============================] - 0s 952us/step - loss: 3.2204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BmBSzpZ4-u"
      },
      "source": [
        "# Making a neural network to give more than one output \n",
        "input_A = keras.layers.Input(shape = [5])\n",
        "input_B = keras.layers.Input(shape = [6])\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "aux_output = keras.layers.Dense(1)(hidden2) # auxilary output \n",
        "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVTgEYLmbPXE",
        "outputId": "411adc8b-43d7-4112-f59d-84e4aae21ddd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 30)           210         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 30)           930         dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 35)           0           input_4[0][0]                    \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            36          concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1)            31          dense_12[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,207\n",
            "Trainable params: 1,207\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKRbGTopbRTr",
        "outputId": "3f1d53b2-4368-4483-f048-3c3634e03b44"
      },
      "source": [
        "# Compiling the model \n",
        "model.compile(loss = ['mse', 'mse'],loss_weights=[0.9, 0.1], optimizer = 'sgd')\n",
        "\n",
        "# Training the model \n",
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
        "    validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        ")\n",
        "\n",
        "# Getting all losses\n",
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test]\n",
        ")\n",
        "\n",
        "print(total_loss, main_loss, aux_loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.5352 - dense_13_loss: 1.4590 - dense_14_loss: 2.2218 - val_loss: 0.8521 - val_dense_13_loss: 0.7951 - val_dense_14_loss: 1.3656\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6071 - dense_13_loss: 0.5437 - dense_14_loss: 1.1785 - val_loss: 0.7211 - val_dense_13_loss: 0.6779 - val_dense_14_loss: 1.1102\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5771 - dense_13_loss: 0.5357 - dense_14_loss: 0.9503 - val_loss: 0.5562 - val_dense_13_loss: 0.5095 - val_dense_14_loss: 0.9765\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4789 - dense_13_loss: 0.4438 - dense_14_loss: 0.7949 - val_loss: 0.5160 - val_dense_13_loss: 0.4807 - val_dense_14_loss: 0.8339\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4562 - dense_13_loss: 0.4275 - dense_14_loss: 0.7149 - val_loss: 0.5141 - val_dense_13_loss: 0.4853 - val_dense_14_loss: 0.7734\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4462 - dense_13_loss: 0.4225 - dense_14_loss: 0.6600 - val_loss: 0.4923 - val_dense_13_loss: 0.4659 - val_dense_14_loss: 0.7295\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4249 - dense_13_loss: 0.4039 - dense_14_loss: 0.6146 - val_loss: 0.4816 - val_dense_13_loss: 0.4567 - val_dense_14_loss: 0.7057\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4239 - dense_13_loss: 0.4043 - dense_14_loss: 0.6008 - val_loss: 0.4766 - val_dense_13_loss: 0.4530 - val_dense_14_loss: 0.6892\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4138 - dense_13_loss: 0.3951 - dense_14_loss: 0.5822 - val_loss: 0.4732 - val_dense_13_loss: 0.4500 - val_dense_14_loss: 0.6823\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4078 - dense_13_loss: 0.3896 - dense_14_loss: 0.5713 - val_loss: 0.4781 - val_dense_13_loss: 0.4557 - val_dense_14_loss: 0.6796\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4220 - dense_13_loss: 0.4033 - dense_14_loss: 0.5897 - val_loss: 0.4639 - val_dense_13_loss: 0.4423 - val_dense_14_loss: 0.6578\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4080 - dense_13_loss: 0.3900 - dense_14_loss: 0.5702 - val_loss: 0.4598 - val_dense_13_loss: 0.4388 - val_dense_14_loss: 0.6486\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.4051 - dense_13_loss: 0.3890 - dense_14_loss: 0.5505 - val_loss: 0.4469 - val_dense_13_loss: 0.4257 - val_dense_14_loss: 0.6370\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3830 - dense_13_loss: 0.3659 - dense_14_loss: 0.5373 - val_loss: 0.4542 - val_dense_13_loss: 0.4352 - val_dense_14_loss: 0.6259\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3862 - dense_13_loss: 0.3706 - dense_14_loss: 0.5269 - val_loss: 0.4559 - val_dense_13_loss: 0.4356 - val_dense_14_loss: 0.6386\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3899 - dense_13_loss: 0.3745 - dense_14_loss: 0.5284 - val_loss: 0.4439 - val_dense_13_loss: 0.4242 - val_dense_14_loss: 0.6211\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3676 - dense_13_loss: 0.3531 - dense_14_loss: 0.4983 - val_loss: 0.4329 - val_dense_13_loss: 0.4146 - val_dense_14_loss: 0.5977\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3616 - dense_13_loss: 0.3479 - dense_14_loss: 0.4849 - val_loss: 0.4269 - val_dense_13_loss: 0.4074 - val_dense_14_loss: 0.6021\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3787 - dense_13_loss: 0.3644 - dense_14_loss: 0.5078 - val_loss: 0.4587 - val_dense_13_loss: 0.4407 - val_dense_14_loss: 0.6204\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3575 - dense_13_loss: 0.3439 - dense_14_loss: 0.4806 - val_loss: 0.4235 - val_dense_13_loss: 0.4047 - val_dense_14_loss: 0.5926\n",
            "162/162 [==============================] - 0s 1ms/step - loss: 3.1224 - dense_13_loss: 3.0049 - dense_14_loss: 4.1803\n",
            "3.122415542602539 3.004873037338257 4.1803059577941895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f81kbFhxcm1f"
      },
      "source": [
        "## Building a model using Subclassing API\n",
        "In, this method we can wrap our model around a class which can help us to do operations on it like loops, if-statements, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soA2MbTgkX09"
      },
      "source": [
        "# Building a model with Subclassing API\n",
        "class WideAndDeep(keras.models.Model):\n",
        "  def __init__(self, units=30, activation='relu', **kwargs): # constructor\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "    self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "    self.main_output = keras.layers.Dense(1)\n",
        "    self.aux_output = keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    input_A, input_B = inputs \n",
        "    hidden1 = self.hidden1(input_B)\n",
        "    hidden2 = self.hidden2(hidden1)\n",
        "    concat = keras.layers.concatenate([input_A, hidden2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden2)\n",
        "    \n",
        "    return main_output, aux_output\n",
        "\n",
        "model = WideAndDeep()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afCniRIGNdvh"
      },
      "source": [
        "## Callbacks and Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUQmkSaBljqp"
      },
      "source": [
        "### Callbacks \n",
        "Callbacks are used to analyse a neural network at different stages of training. Callbacks can be used to save the model at different stages as well as to perform early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGX7e3NDNcc5",
        "outputId": "dd56a15c-2757-451f-e2b4-8b6758f0d335"
      },
      "source": [
        "# Making a neural network with model saving and early stopping callbacks \n",
        "# Making the model \n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
        "        keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "# Making callbacks \n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True) # Model saving \n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data = (X_valid, y_valid))\n",
        "\n",
        "# Evaluating \n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "y_pred = model.predict(X_test[:3])\n",
        "print(y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.2923 - val_loss: 0.6700\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5641 - val_loss: 0.4876\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.4757\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4294 - val_loss: 0.4594\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.4276 - val_loss: 0.4392\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3951 - val_loss: 0.4482\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3838 - val_loss: 0.4265\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.4242\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3718 - val_loss: 0.4362\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3839 - val_loss: 0.4218\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3827 - val_loss: 0.4130\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3577 - val_loss: 0.4085\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3706 - val_loss: 0.4100\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3636 - val_loss: 0.4057\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.4030\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.4059\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.4011\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.4061\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4069\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3975\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.4063\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3487 - val_loss: 0.4095\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3976\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.4068\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3952\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3455 - val_loss: 0.4043\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.4005\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3937\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3340 - val_loss: 0.4146\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3358 - val_loss: 0.3928\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3992\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3386 - val_loss: 0.3923\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3955\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3947\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3916\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3887\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3887\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3833\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3899\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3347 - val_loss: 0.3937\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3160 - val_loss: 0.3882\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3183 - val_loss: 0.4172\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3381 - val_loss: 0.3855\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3899\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3870\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3805\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3342 - val_loss: 0.3837\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3813\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3156 - val_loss: 0.3898\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3793\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3844\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3264 - val_loss: 0.3890\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3113 - val_loss: 0.3841\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3781\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3066 - val_loss: 0.3734\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3088 - val_loss: 0.3747\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3040 - val_loss: 0.3740\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3876\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2937 - val_loss: 0.3884\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2941 - val_loss: 0.3814\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3138 - val_loss: 0.3774\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3105 - val_loss: 0.3933\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3034 - val_loss: 0.3824\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3116 - val_loss: 0.3667\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3055 - val_loss: 0.3883\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2970 - val_loss: 0.3808\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2897 - val_loss: 0.3770\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2968 - val_loss: 0.3705\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2911 - val_loss: 0.3922\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.3802\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3059 - val_loss: 0.3855\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2928 - val_loss: 0.3715\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3853\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3077 - val_loss: 0.3748\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3900\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2899 - val_loss: 0.3765\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2935 - val_loss: 0.3781\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3080 - val_loss: 0.3837\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3692\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2975 - val_loss: 0.3660\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3098 - val_loss: 0.3806\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3174 - val_loss: 0.3832\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2992 - val_loss: 0.3772\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3736\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3704\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3011 - val_loss: 0.3626\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3929\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3629\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3014 - val_loss: 0.3825\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3866\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2964 - val_loss: 0.3748\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3778\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3029 - val_loss: 0.3701\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3114 - val_loss: 0.3710\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3005 - val_loss: 0.3688\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2896 - val_loss: 0.3807\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.2947 - val_loss: 0.3819\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3042 - val_loss: 0.3659\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3111 - val_loss: 0.3816\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3669\n",
            "162/162 [==============================] - 0s 865us/step - loss: 1.5351\n",
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc1f8553290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[[4.4069896 ]\n",
            " [0.49960858]\n",
            " [0.48914427]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkC_rOAyOKpx"
      },
      "source": [
        "# Custom callback for showing val_loss/loss at the end of epoch \n",
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    print(\"\\nval/train: {:.2f}\".format(logs['val_logs'] / logs['loss']))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6XlLrI1PvNO"
      },
      "source": [
        "### Tensorboard \n",
        "Tensorboard is a graphical tool provided by Tensorflow to visualise the performance of our neural network. It does this by taking the logs generated during the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx8FZjLJUeSd"
      },
      "source": [
        "# Creating log directory returning function \n",
        "import os\n",
        "import time \n",
        "\n",
        "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
        "\n",
        "def get_run_logdir():\n",
        "  run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "  return os.path.join(root_logdir, run_id)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jCIiRyhVo3b",
        "outputId": "40e874d3-b1c5-4349-f83a-8a236a5aad6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Making a model with tensorboard callback \n",
        "# Making the model \n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation='relu', input_shape = X_train.shape[1:]),\n",
        "        keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Logs directory \n",
        "run_logdir = get_run_logdir()\n",
        "\n",
        "# Making tensorboard callback \n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data = (X_valid, y_valid),\n",
        "                    callbacks=[tensorboard_cb])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0984 - val_loss: 0.8784\n",
            "Epoch 2/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.7877\n",
            "Epoch 3/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.5800 - val_loss: 0.4954\n",
            "Epoch 4/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4576 - val_loss: 0.4754\n",
            "Epoch 5/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4373 - val_loss: 0.4572\n",
            "Epoch 6/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4170 - val_loss: 0.4493\n",
            "Epoch 7/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3982 - val_loss: 0.4435\n",
            "Epoch 8/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.4045 - val_loss: 0.4420\n",
            "Epoch 9/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3872 - val_loss: 0.4433\n",
            "Epoch 10/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3897 - val_loss: 0.4374\n",
            "Epoch 11/30\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.4398\n",
            "Epoch 12/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3806 - val_loss: 0.4272\n",
            "Epoch 13/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3817 - val_loss: 0.4299\n",
            "Epoch 14/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3751 - val_loss: 0.4249\n",
            "Epoch 15/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.4218\n",
            "Epoch 16/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.4342\n",
            "Epoch 17/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3680 - val_loss: 0.4198\n",
            "Epoch 18/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.4195\n",
            "Epoch 19/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3578 - val_loss: 0.4212\n",
            "Epoch 20/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.4163\n",
            "Epoch 21/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3419 - val_loss: 0.4181\n",
            "Epoch 22/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.4177\n",
            "Epoch 23/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3450 - val_loss: 0.4100\n",
            "Epoch 24/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.4250\n",
            "Epoch 25/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3609 - val_loss: 0.4210\n",
            "Epoch 26/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3542 - val_loss: 0.4203\n",
            "Epoch 27/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3416 - val_loss: 0.4050\n",
            "Epoch 28/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3512 - val_loss: 0.4080\n",
            "Epoch 29/30\n",
            "363/363 [==============================] - 1s 1ms/step - loss: 0.3440 - val_loss: 0.4151\n",
            "Epoch 30/30\n",
            "363/363 [==============================] - 0s 1ms/step - loss: 0.3512 - val_loss: 0.4059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-8RP4CWJ62",
        "outputId": "4968a369-b4d8-4f4a-f27f-f89a4ff47e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOWzzjHIWhzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}